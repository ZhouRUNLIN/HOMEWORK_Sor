{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4TJrAm4JFr9V"
   },
   "source": [
    "\n",
    "\n",
    "\n",
    "Objectifs:\n",
    "Savoir organiser des données en pages pour permettre de modifier un tuple en ne modifiant qu'une seule page.\n",
    "\n",
    "Comprendre les méthodes d'accès suivantes :\n",
    "\n",
    "*   Lecture séquentielle d'une fichier : \"table access full\"\n",
    "*   Lecture d'un tuple dont on connait le rowid : \"table access by index rowid\"\n",
    "*   Opération de sélection par lecture séquentielle et filtrage\n",
    "\n",
    "Comprendre les méthodes d'indexation :\n",
    "\n",
    "*   Créer un index\n",
    "*   Opération de sélection par index et lecture par rowid\n",
    "\n",
    "Mise à jour de données\n",
    "*   Sélectionner un tuple et modifier un de ses attributs\n",
    "*   Modifier l'index en conséquence lorsque l'attibut modifié est indexé\n",
    "\n",
    "Persistence\n",
    "*   Stocker un index (dans plusieurs pages) pour le reconstruire plus rapidement\n",
    "*   Adapter en conséquence les opérations de modification de l'index\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vZzLUr_l_Wfb"
   },
   "source": [
    "# TP 1 et 2 : Accès aux données avec index\n",
    "# sujet\n",
    "\n",
    "date de modification : 18/01/2024\n",
    "\n",
    "BINOME\n",
    "\n",
    "NOM 1: ZHOU\n",
    "\n",
    "Prénom 1: runlin\n",
    "\n",
    "Numéro : 28717281\n",
    "\n",
    "NOM 2: ZHANG \n",
    "\n",
    "Prénom 2: zhile\n",
    "\n",
    "Numéro : 21201131\n",
    "\n",
    "TP à rendre : **REDIGER des explications détaillées et argumentées** pour les solutions que vous proposez"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aodlGU01gLqK",
    "outputId": "4f1a6b46-c2f6-4836-8aa2-d6de99106742"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "le nom de la table est T\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil as sh\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "# from sortedcontainers import SortedDict\n",
    "import sortedcontainers\n",
    "\n",
    "from string import ascii_lowercase\n",
    "import time\n",
    "\n",
    "# le nom de la table\n",
    "TABLE = \"T\"\n",
    "print(\"le nom de la table est\", TABLE)\n",
    "\n",
    "\n",
    "# le nom du fichier qui contient les données de la table\n",
    "def nom_fichier(table):\n",
    "    return table + \".csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cRKX2fgx_gYT"
   },
   "source": [
    "# Générer les données du TP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ezxoKUCxtASX"
   },
   "source": [
    "Création du fichier contenant un exemple de données.\n",
    "Ce sont des données au format csv. On suppose que chaque ligne correspond à un tuple d'une table **T** ayant *n* attributs :\n",
    "\n",
    "$$ T (a_0, a_1, a_2, ..., a_{n-1})$$\n",
    "\n",
    "Le premier attribut $a_0$ est unique.\n",
    "\n",
    "Les attributs $a_1$ à $a_{n-2}$ ne sont pas uniques : il y a en moyenne $2^k$ tuples par valeurs de $a_k$ soit 2 tuples par valeur de $a_1$ et 4 tuples par valeurs de $a_2$.\n",
    "\n",
    "Les attributs sont des nombres entiers, multiples de 10, sauf le dernier qui est une chaine de caractères (on choisit des mutliples de 10 pour représenter le cas plus général de domaines contenant des valeurs non consécutives).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TIvmnhsTryK4",
    "outputId": "9b93f388-1086-4561-d2d4-c403120f92ba"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "écriture des données dans le fichier T.csv\n",
      "durée pour générer 2000000 lignes : 5.8 s\n"
     ]
    }
   ],
   "source": [
    "# dure environ 20s pour 2M lignes\n",
    "# dure environ 40s pour 5M lignes\n",
    "\n",
    "\n",
    "def genere_fichier(nb_lignes, nb_attributs, longueur_dernier_attribut, table):\n",
    "  # attribut_chaine_caracteres = \"\".join(choice(ascii_lowercase) for i in range(longueur_dernier_attribut))\n",
    "  attribut_chaine_caracteres = ''.join('-' for i in range(longueur_dernier_attribut))\n",
    "  # print(\"le dernier attribut de chaque tuple est la chaine de caracètes :\", attribut_chaine_caracteres)\n",
    "\n",
    "  # reproductibilité des données générées\n",
    "  rng = np.random.default_rng(seed=1)\n",
    "\n",
    "  data={}\n",
    "\n",
    "  # le premier attribut est unique.\n",
    "  nb_valeurs_distinctes = nb_lignes\n",
    "  data['a0'] = 10 * rng.permutation(np.arange(nb_valeurs_distinctes))\n",
    "\n",
    "  # les attributs suivants ont des domaines plus petits :\n",
    "  for i in range(1, nb_attributs):\n",
    "    # on divise le domaine par 2 à chaque itération\n",
    "    nb_valeurs_distinctes = max(2, int(nb_valeurs_distinctes / 2))\n",
    "    data[f'a{i}'] = 10 * rng.integers(0, nb_valeurs_distinctes, nb_lignes)\n",
    "\n",
    "  # on concatène \"verticalement\" les attributs dans un dataframe pour former des tuples sur lesquels on peut itérer.\n",
    "  df = pd.DataFrame(data)\n",
    "  # rmq: le dernier attribut est une chaine de caractères\n",
    "  b = [str(e)[1:-1] + f\",{attribut_chaine_caracteres}\\n\" for e in df.itertuples(index=False, name=None)]\n",
    "\n",
    "  # on stocke les données dans un fichier\n",
    "  fichier = nom_fichier(table)\n",
    "  print(\"écriture des données dans le fichier\", fichier)\n",
    "  with open(fichier, \"w\") as f:\n",
    "    # écriture groupée de tous les tuples\n",
    "    f.write(''.join(b))\n",
    "\n",
    "nb_lignes = 2 * 1000 * 1000\n",
    "# nb_lignes = 5 * 1000 * 1000\n",
    "nb_attributs = 7\n",
    "longueur_dernier_attribut = 100\n",
    "\n",
    "t1 = time.time()\n",
    "genere_fichier(nb_lignes, nb_attributs, longueur_dernier_attribut, TABLE)\n",
    "print(f\"durée pour générer {nb_lignes} lignes :\", round(time.time() - t1, 1), \"s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ogkKxanaBHQF"
   },
   "source": [
    "On affiche le début et la fin du fichier et son nombre de lignes ( = card(T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1aMC3Y6yryK-",
    "outputId": "45427080-64ff-4821-fac7-93dcafad21f9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "debut de T.csv :\n",
      "19512870, 5751570, 1235270, 1344040, 1139220, 359300, 261790,----------------------------------------------------------------------------------------------------\n",
      "3462320, 3047440, 4558650, 2392580, 332870, 445910, 35390,----------------------------------------------------------------------------------------------------\n",
      "\n",
      "fin de T.csv : \n",
      "4418430, 9611540, 268500, 660850, 881140, 311230, 273070,----------------------------------------------------------------------------------------------------\n",
      "1896950, 9749280, 4493840, 1757100, 1083240, 323240, 177530,----------------------------------------------------------------------------------------------------\n",
      "\n",
      "nombre de lignes:\n",
      " 2000000 T.csv\n"
     ]
    }
   ],
   "source": [
    "%%bash -s \"{TABLE}.csv\"\n",
    "echo \"debut de $1 :\"\n",
    "head -n 2 $1\n",
    "echo\n",
    "echo \"fin de $1 : \"\n",
    "tail -n 2 $1\n",
    "echo\n",
    "echo \"nombre de lignes:\"\n",
    "wc -l $1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5gm8_3CY_odp"
   },
   "source": [
    "# Lecture séquentielle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NZaYoqeiHO2p"
   },
   "source": [
    "On définit un *iterateur* pour lire séquentiellement chaque ligne de la table stockée entièrement dans un seul fichier.\n",
    "Le mot python *yield* permet de définir un itérateur qui est retourné par la fonction.\n",
    "\n",
    "Cet itérateur est invoqué pour lire la table et appliquer un filtre.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nSX2XxLx_tBa",
    "outputId": "59cb964c-8d3a-4063-b429-31a2ec8d9d28"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valeur recherchée : 1798348\n",
      "durée : 2.135 s\n"
     ]
    }
   ],
   "source": [
    "def lecture_sequentielle(table):\n",
    "  fichier = nom_fichier(table)\n",
    "  with open(fichier, \"r\") as f:\n",
    "    for i, line in enumerate(f):\n",
    "      yield i, line\n",
    "\n",
    "def filtrer_table(table, valeur_recherchee):\n",
    "  for i, line in lecture_sequentielle(table):\n",
    "      a = int(line.split(',')[0])\n",
    "      if a == valeur_recherchee :\n",
    "        print(f\"ligne {i} :\", line.strip())\n",
    "\n",
    "\n",
    "nb_valeurs_distinctes = nb_lignes\n",
    "s = np.random.randint(nb_valeurs_distinctes)\n",
    "print(\"valeur recherchée :\", s)\n",
    "\n",
    "t1 = time.time()\n",
    "filtrer_table(TABLE, s)\n",
    "print(\"durée :\", round(time.time() - t1, 3), \"s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qlmFE3aZTBWC"
   },
   "source": [
    "# Découper une table en pages\n",
    "\n",
    "On organise les données en pages.\n",
    "Pour faciliter le TP, chaque page est représentée par un \"petit\" fichier mais en réalité une page est un bloc d'un fichier.\n",
    "\n",
    "Dans la suite du TP, on accédera toujours aux pages.\n",
    "Le fichier créé initialement, contenant tous les tuples, ne sera plus utilisé."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kOEddKG8PHDF",
    "outputId": "983c0891-a68b-466c-fc93-7608fe09fddb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "les pages sont stockées dans le dossier T_pages\n",
      "nb pages créées : 2000\n"
     ]
    }
   ],
   "source": [
    "def page_dir_name(table):\n",
    "  return table + \"_pages\"\n",
    "\n",
    "def decoupe_table_en_pages(table, nb_tuple_par_page):\n",
    "  page_dir = page_dir_name(table)\n",
    "\n",
    "  # vider le dossier qui contiendra les pages\n",
    "  if(os.path.exists(page_dir)):\n",
    "    sh.rmtree(page_dir)\n",
    "  os.makedirs(page_dir, exist_ok=True)\n",
    "\n",
    "  # lire le fichier contenant tous les tuples\n",
    "  p=0\n",
    "  lines = []\n",
    "  for i, line in lecture_sequentielle(table):\n",
    "    lines.append(line)\n",
    "    if (i+1) % nb_tuple_par_page == 0:\n",
    "\n",
    "      # créer une page\n",
    "      p += 1\n",
    "      with open(page_dir + f\"/page{p}\", \"w\") as fp:\n",
    "        fp.write(''.join(lines))\n",
    "      lines = []\n",
    "\n",
    "  # créer une dernière page, si nécessaire\n",
    "  if len(lines) > 0:\n",
    "    p +=1\n",
    "    with open(page_dir + f\"/page{p}\", \"w\") as fp:\n",
    "        fp.write(''.join(lines))\n",
    "\n",
    "  print(\"nb pages créées :\", p)\n",
    "\n",
    "\n",
    "print(\"les pages sont stockées dans le dossier\", page_dir_name(TABLE) )\n",
    "\n",
    "decoupe_table_en_pages(TABLE, nb_tuple_par_page=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hqaml72_bXkj"
   },
   "source": [
    "Afficher (pour quelques pages) le nombre de tuples contenus dans une page"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bMqMNrHbbWof"
   },
   "source": [
    "une solution en bash :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qEX48QWEClJD",
    "outputId": "64bf3b18-b763-4a19-e78c-41e196445d3b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    1000 T_pages/page1\n",
      "    1000 T_pages/page10\n",
      "    1000 T_pages/page100\n"
     ]
    }
   ],
   "source": [
    "%%bash -s \"$TABLE\"\n",
    "wc -l $1_pages/* | head -n 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m3OlZo1ZbToW"
   },
   "source": [
    "une autre solution en python :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "99NDkIXsXKrf",
    "outputId": "3cd560aa-39b8-4a51-a9b2-0e0a0eb3d030"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "la page page1749 contient 1000 lignes\n",
      "la page page1056 contient 1000 lignes\n",
      "la page page863 contient 1000 lignes\n"
     ]
    }
   ],
   "source": [
    "page_dir = page_dir_name(TABLE)\n",
    "l = os.listdir(page_dir)\n",
    "random.seed(1)\n",
    "for i in range(3):\n",
    "  une_page = random.choice(l)\n",
    "  with open(page_dir + f\"/{une_page}\", 'r') as fp:\n",
    "    lines = len(fp.readlines())\n",
    "    print(f\"la page {une_page} contient {lines} lignes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y4XDZAmbcUQb"
   },
   "source": [
    "# Lecture séquentielle d'une table découpée en pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fPVOrVpKccUG",
    "outputId": "07a93329-da22-4594-f49f-f10861d2e185"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valeur recherchée : 773357\n",
      "durée : 2.78 s\n"
     ]
    }
   ],
   "source": [
    "def lecture_sequentielle_par_page(table):\n",
    "  page_dir = page_dir_name(table)\n",
    "  nb_pages = len(os.listdir(page_dir))\n",
    "  for p in range(1, nb_pages+1) :\n",
    "    with open(page_dir + f\"/page{p}\", \"r\") as f:\n",
    "      for i, line in enumerate(f):\n",
    "        tuple_courant = line.strip().split(',')\n",
    "        yield p, i, tuple_courant\n",
    "\n",
    "def filtrer_table_par_pages(table, valeur_recherchee):\n",
    "  for page, position, tuple_courant in lecture_sequentielle_par_page(table):\n",
    "    attribut0 = int(tuple_courant[0])\n",
    "    if attribut0 == valeur_recherchee :\n",
    "      print(f\"page {page}, ligne {position} :\", tuple_courant)\n",
    "\n",
    "search = np.random.randint(nb_lignes)\n",
    "print(\"valeur recherchée :\", search)\n",
    "\n",
    "t1 = time.time()\n",
    "filtrer_table_par_pages(TABLE, search)\n",
    "print(\"durée :\", round(time.time() - t1, 2), \"s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UcmdLaQ5ruBJ"
   },
   "source": [
    "# Lecture d'un tuple dans une page"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ow_RkbQ_U8qs"
   },
   "source": [
    "Cette fonction retourne le tuple situé dans la page *num_page* et à la position *position*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "F4tYi4xCrxFG",
    "outputId": "6f9614a5-5884-492b-cf22-367dd6596581"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17233030, 9546020, 4178470, 117430, 31540, 530090, 250650,----------------------------------------------------------------------------------------------------\n",
      "done in 2.4 ms\n"
     ]
    }
   ],
   "source": [
    "def lecture_tuple(table, num_page, position):\n",
    "  page_dir = page_dir_name(table)\n",
    "  with open(page_dir + f\"/page{num_page}\", \"r\") as f:\n",
    "    lines = f.readlines()\n",
    "    return lines[position].strip()\n",
    "\n",
    "t1 = time.time()\n",
    "print(lecture_tuple(TABLE, 123, 456))\n",
    "print(\"done in\", round((time.time() - t1)*1000, 1), \"ms\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5mD_xZjLxXLD"
   },
   "source": [
    "# Exercice 1 : Créer un index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vNgxRQtOTwOH"
   },
   "source": [
    "## Créer un index unique pour l'attribut $a_0$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TCJyftyiXyFo"
   },
   "source": [
    "On sait que $a_0$ est unique.\n",
    "Une entrée de l'index associe une *clé* à une *valeur* :\n",
    "*   La *clé* est la valeur du premier attribut.\n",
    "*   La *valeur* est un **rowid** formé des informations (page, position)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "id": "Fhy4IJ0bxWHD"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "durée  5.481 s\n"
     ]
    }
   ],
   "source": [
    "def creation_index_unique(table):\n",
    "    index = {}\n",
    "    page_dir = page_dir_name(table)\n",
    "    nb_pages = len(os.listdir(page_dir))\n",
    "    for i in range(1, nb_pages + 1):\n",
    "        with open(page_dir + \"/page\"+ str(i), 'r') as fp:\n",
    "            for pos, tuplePage in enumerate(fp):\n",
    "                index[float(tuplePage.split(\",\")[0])] = (i, pos)    \n",
    "\n",
    "    return sortedcontainers.SortedDict(index)  # TODO\n",
    "\n",
    "t1 = time.time()\n",
    "INDEX_UNIQUE_a0 = creation_index_unique(TABLE)\n",
    "print(\"durée \", round(time.time() - t1, 3), \"s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "id": "_WbJm39uuwgn"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14267440 (1727, 971)\n"
     ]
    }
   ],
   "source": [
    "#vérifier l'index\n",
    "s = 10 * np.random.randint(nb_lignes)\n",
    "print(s, INDEX_UNIQUE_a0[s])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JcUQ8XRcT1dg"
   },
   "source": [
    "## Créer un index non unique pour l'attribut $a_i$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M4AtpJouWSmB"
   },
   "source": [
    "On donne un nom de table et le numéro $i$ de l'attribut $a_i$ de la table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "id": "gxJC1-m-VRC5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "duree de création de l'index pour l'attribut a2: 6.638 s\n"
     ]
    }
   ],
   "source": [
    "def creation_index(table, numero_attribut):\n",
    "    index = {}\n",
    "    page_dir = page_dir_name(table)\n",
    "    nb_pages = len(os.listdir(page_dir))\n",
    "    for i in range(1, nb_pages + 1):\n",
    "        with open(page_dir + \"/page\"+ str(i), 'r') as fp:\n",
    "            for pos, tuplePage in enumerate(fp):\n",
    "                key = float(tuplePage.split(\",\")[numero_attribut])\n",
    "                if key in index.keys():\n",
    "                    index[key].append((i, pos))\n",
    "                else:\n",
    "                    index[key] = [(i, pos)]\n",
    "\n",
    "    return sortedcontainers.SortedDict(index)\n",
    "\n",
    "\n",
    "t1 = time.time()\n",
    "INDEX_a2 = creation_index(TABLE, 2)\n",
    "print(\"duree de création de l'index pour l'attribut a2:\", round(time.time() - t1, 3), \"s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "id": "INubLbmNttNJ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valeur recherchée : 2768390\n",
      "(608, 545)\n",
      "(690, 627)\n",
      "(703, 713)\n",
      "(1274, 763)\n",
      "(1467, 722)\n",
      "(1721, 604)\n",
      "(1752, 842)\n"
     ]
    }
   ],
   "source": [
    "# # vérifier l'index\n",
    "s = 10 * np.random.randint(nb_valeurs_distinctes/4)\n",
    "print(\"valeur recherchée :\", s)\n",
    "for r in INDEX_a2[s]:\n",
    "  print(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-qA7hCef5Kfa"
   },
   "source": [
    "# Exerccie 2 : Accès par index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J0zrHPfGJjzm"
   },
   "source": [
    "## Accès ciblé\n",
    "\n",
    "On veut retrouver les tuples telq qu'un attribut indexé a une valeur donnée."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EEEUaCYqhIaB"
   },
   "source": [
    "### Index unique scan.\n",
    "On recherche un unique tuple dont l'attribut indexé a une valeur donnée (car l'attribut est unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "id": "PH3f5bz-5JTu"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valeur recherchée : 19879230\n",
      "resulat: 19879230, 6042930, 4235030, 608740, 739590, 139530, 80,----------------------------------------------------------------------------------------------------\n",
      "done in 1.77 ms\n"
     ]
    }
   ],
   "source": [
    "def acces_par_index_unique(index_unique, table, valeur_recherchee):\n",
    "    page, pos = index_unique[valeur_recherchee] \n",
    "    return lecture_tuple(table, page, pos)\n",
    "\n",
    "s = 10 * np.random.randint(nb_lignes)\n",
    "print(\"valeur recherchée :\", s)\n",
    "\n",
    "t1 = time.time()\n",
    "tuple = acces_par_index_unique(INDEX_UNIQUE_a0, TABLE, s)\n",
    "print(\"resulat:\", tuple)\n",
    "print(\"done in\", round((time.time() - t1)*1000, 2), \"ms\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xfR_0QAShCJi"
   },
   "source": [
    "### Index scan\n",
    "Accès pour rechercher les tuples dont l'attribut indexé a une valeur donnée. On suppose que l'attribut n'est pas unique et que plusieurs tuples sont retrouvés"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "id": "4eyjynk_hZer"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valeur recherchée : 3998410\n",
      "3107010, 6645800, 3998410, 327250, 262850, 229190, 205100,----------------------------------------------------------------------------------------------------\n",
      "12464550, 871810, 3998410, 1255330, 431690, 54840, 9920,----------------------------------------------------------------------------------------------------\n",
      "2497370, 9945590, 3998410, 495680, 1097460, 73950, 308770,----------------------------------------------------------------------------------------------------\n",
      "1727290, 6161920, 3998410, 906870, 110990, 61260, 234610,----------------------------------------------------------------------------------------------------\n",
      "3875870, 6653360, 3998410, 1818940, 411710, 504760, 134920,----------------------------------------------------------------------------------------------------\n",
      "done in 12.86 ms\n"
     ]
    }
   ],
   "source": [
    "def acces_par_index(index, table, valeur_recherchee):\n",
    "    listPagePos = index[valeur_recherchee] \n",
    "    res = []\n",
    "    for page, pos in listPagePos:\n",
    "        res.append(lecture_tuple(table, page, pos))\n",
    "    return res\n",
    "\n",
    "\n",
    "\n",
    "s = 10* np.random.randint(nb_lignes/4)\n",
    "print(\"valeur recherchée :\", s)\n",
    "\n",
    "t1 = time.time()\n",
    "for t in acces_par_index(INDEX_a2, TABLE, s):\n",
    "  print(t)\n",
    "print(\"done in\", round((time.time() - t1)*1000, 2), \"ms\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "afvN2LWhJs0V"
   },
   "source": [
    "## Accès par intervalle\n",
    "Index range scan\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CIL6jrUuaPMO"
   },
   "source": [
    "### Accès par intervalle sur un attribut unique\n",
    "Accès pour rechercher les tuples dont l'attribut indexé est unique et a une valeur comprise dans un intervalle donné.\n",
    "Indications, votre solution doit prendre en compte les exigences suivantes :\n",
    "*  Les valeurs recherchées ne sont pas connues à l'avance. On sait seulement qu'elles sont incluses dans un intervalle. Ne pas supposer qu'on recherche des entiers consécutifs.\n",
    "*  Les bornes de l'intervalle ne sont pas parmi les valeurs existantes de l'attribut. Par exemple, on peut rechercher les valeurs de $a_0$ comprises dans l'intervalle  [23 , 45].\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "id": "8maKd3mdqxKU"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "l'indice de la première clé à retrouver est : 3\n",
      "la première clé retrouvée est: 30.0\n",
      "la valeur à retrouver est : (1783, 941)\n"
     ]
    }
   ],
   "source": [
    "# Exemple pour retrouver la première entrée de l'intervalle [23,45]\n",
    "\n",
    "indice = INDEX_UNIQUE_a0.bisect_left(23)\n",
    "print(\"l'indice de la première clé à retrouver est :\", indice)\n",
    "cle = INDEX_UNIQUE_a0.keys()[indice]\n",
    "print(\"la première clé retrouvée est:\", cle)\n",
    "print(\"la valeur à retrouver est :\",  INDEX_UNIQUE_a0[cle])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "id": "EGEO1PheSEdT"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valeur recherchée : 73730\n",
      "done in 0.0 s\n",
      "[(1783, 941), (828, 168)]\n"
     ]
    }
   ],
   "source": [
    "def acces_intervalle_par_index_unique(index_unique, table, borne_inf, borne_sup):\n",
    "    posInf = index_unique.bisect_left(borne_inf)\n",
    "    posSup = index_unique.bisect_left(borne_sup)\n",
    "    listPagePos = []\n",
    "    for index in range(posInf, posSup):\n",
    "        cle = index_unique.keys()[index]\n",
    "        listPagePos.append(index_unique[cle])\n",
    "    return listPagePos\n",
    "\n",
    "s = 10 * np.random.randint(nb_valeurs_distinctes/4)\n",
    "print(\"valeur recherchée :\", s)\n",
    "\n",
    "t1 = time.time()\n",
    "res = acces_intervalle_par_index_unique(INDEX_UNIQUE_a0, TABLE, 23, 45)\n",
    "print(\"done in\", round(time.time() - t1, 2), \"s\")\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nDaG7WelaQrG"
   },
   "source": [
    "### Accès par intervalle sur un attribut NON unique\n",
    "Accès pour rechercher les tuples dont l'attribut indexé n'est **pas** unique et a une valeur comprise dans un intervalle donné.\n",
    "Votre solution doit prendre en compte les mêmes exigences que dans la question précédente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "id": "KQEYfcoEak5A"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valeur recherchée : 1593840\n",
      "done in 0.0 s\n",
      "[(647, 461), (695, 621), (1127, 583), (1224, 492), (1365, 257), (1762, 744), (17, 711), (431, 51), (698, 16), (977, 922), (1495, 411), (155, 42), (920, 445), (1978, 65)]\n"
     ]
    }
   ],
   "source": [
    "def acces_intervalle_par_index(index, table, borne_inf, borne_sup):\n",
    "    posInf = index.bisect_left(borne_inf)\n",
    "    posSup = index.bisect_left(borne_sup)\n",
    "    listPagePos = []\n",
    "    for index_ in range(posInf, posSup):\n",
    "        cle = index.keys()[index_]\n",
    "        listPagePos+=index[cle]\n",
    "    return listPagePos\n",
    "\n",
    "\n",
    "s = 10 * np.random.randint(nb_valeurs_distinctes / 4)\n",
    "print(\"valeur recherchée :\", s)\n",
    "\n",
    "t1 = time.time()\n",
    "res = acces_intervalle_par_index(INDEX_a2, TABLE, s + 3, s + 33)\n",
    "print(\"done in\", round(time.time() - t1, 2), \"s\")\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7Rjm99DrKR8t"
   },
   "source": [
    "# Exercice 3 : Mise à jour de données\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7np5NI8OKK6z"
   },
   "source": [
    "## Modifier la valeur d'un attribut d'un ou plusieurs tuples\n",
    "\n",
    "Cela correspond à l'insctruction UPDATE table SET ... WHERE ...\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z7aN87BOuEbq"
   },
   "source": [
    "### Modification d'un seul tuple\n",
    "\n",
    "On donne une valeur *v* de l'attribut clé $a_0$. Ajouter 1 à l'attribut $a_1$. Cela correspond à l'instruction\n",
    "\n",
    "update T\n",
    "set a1 = a1+10\n",
    "where a0 = *v*\n",
    "\n",
    "Après la modification, accéder aux données pour vérifier que le tuple a bien été modifié. Par exemple, invoquer la fonction\n",
    "acces_par_index_unique(index, table, v)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "id": "RCRwCGlwKlEK"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuple before changing : \n",
      "30, 3412960, 992630, 2228230, 741740, 516750, 256590,----------------------------------------------------------------------------------------------------\n",
      "Tuple after changing : \n",
      "30,3412970, 992630, 2228230, 741740, 516750, 256590,----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "def update_unique(index, table, v, addNum):\n",
    "    \"\"\" La fonction retourne 1 si nous réussirons à modifier la base de données\n",
    "                et retourne 0 sinon\"\"\"\n",
    "    if v not in index.keys():\n",
    "        print(\"Err : valeur recherchee not existe\")\n",
    "        return 0\n",
    "    # init \n",
    "    page, pos = index[v]\n",
    "    page_dir = page_dir_name(table)\n",
    "    file_path = f\"{page_dir}/page{page}\"\n",
    "    # lire sur le ficher\n",
    "    with open(file_path, 'r') as fp:\n",
    "        lines = fp.readlines()\n",
    "    # modifier le tuple corresponde\n",
    "    line = lines[pos].split(\",\")\n",
    "    line[1] = str(int(line[1]) + addNum)\n",
    "    lines[pos] = \",\".join(line)\n",
    "    # ecrire sur le ficher\n",
    "    with open(file_path, 'w') as fp:\n",
    "        fp.writelines(lines)\n",
    "    return 1\n",
    "\n",
    "# before changing \n",
    "valRecherchee = 30\n",
    "PAGE, POS = INDEX_UNIQUE_a0[valRecherchee]\n",
    "print(\"Tuple before changing : \")\n",
    "print(lecture_tuple(TABLE, PAGE, POS))\n",
    "# after changing \n",
    "update_unique(INDEX_UNIQUE_a0, TABLE, 30,10)\n",
    "print(\"Tuple after changing : \")\n",
    "print(lecture_tuple(TABLE, PAGE, POS))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vdexpmRuKfs2"
   },
   "source": [
    "### Modification de plusieurs tuples\n",
    "\n",
    "On donne une valeur *v* de l'attribut $a_2$ qui n'est pas unique. Ajouter 1 à l'attribut $a_3$ de tous les tuples pour lesquels $a_2 = v$\n",
    "\n",
    "update T set a3 = a3+10 where a2=v\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "id": "J_18vhvxM61d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The set of Tuple before changing : \n",
      "6205950, 8585550, 30, 1966620, 388790, 617990, 81050,----------------------------------------------------------------------------------------------------\n",
      "9028020, 4232240, 30, 1507340, 414170, 480850, 54010,----------------------------------------------------------------------------------------------------\n",
      "10451500, 5134390, 30, 2206910, 689690, 289210, 115540,----------------------------------------------------------------------------------------------------\n",
      "12116110, 3966910, 30, 1310440, 241660, 371740, 147360,----------------------------------------------------------------------------------------------------\n",
      "The set of Tuple after changing : \n",
      "6205950, 8585550, 30,1966630.0, 388790, 617990, 81050,----------------------------------------------------------------------------------------------------\n",
      "9028020, 4232240, 30,1507350.0, 414170, 480850, 54010,----------------------------------------------------------------------------------------------------\n",
      "10451500, 5134390, 30,2206920.0, 689690, 289210, 115540,----------------------------------------------------------------------------------------------------\n",
      "12116110, 3966910, 30,1310450.0, 241660, 371740, 147360,----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "def update_plusieurs(index, table, v, addNum):\n",
    "    \"\"\" La fonction retourne le nombre de donnees qu'on modifier dans cette operation \n",
    "                et retourne 0 si on ne trouve pas la valeur correspondant\"\"\"\n",
    "    if v not in index.keys():\n",
    "        print(\"Err : valeur recherchee not existe\")\n",
    "        return 0\n",
    "    # init\n",
    "    listPagePos = index[v]\n",
    "    page_dir = page_dir_name(table)\n",
    "    for page, pos in listPagePos:\n",
    "        file_path = f\"{page_dir}/page{page}\"\n",
    "        # lire sur le ficher\n",
    "        with open(file_path, 'r') as fp:\n",
    "            lines = fp.readlines()\n",
    "        # modifier le tuple corresponde\n",
    "        line = lines[pos].split(\",\")\n",
    "        line[3] = str(float(line[3]) + addNum)\n",
    "        lines[pos] = \",\".join(line)\n",
    "        # ecrire sur le ficher\n",
    "        with open(file_path, 'w') as fp:\n",
    "            fp.writelines(lines)\n",
    "    return len(listPagePos)\n",
    "\n",
    "# before changing \n",
    "valRecherchee = 30\n",
    "print(\"The set of Tuple before changing : \")\n",
    "for PAGE, POS in INDEX_a2[valRecherchee]:\n",
    "    print(lecture_tuple(TABLE, PAGE, POS))\n",
    "# after changing \n",
    "update_plusieurs(INDEX_a2, TABLE, 30, 10)\n",
    "print(\"The set of Tuple after changing : \")\n",
    "for PAGE, POS in INDEX_a2[valRecherchee]:\n",
    "    print(lecture_tuple(TABLE, PAGE, POS))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8zAZws5_KaL8"
   },
   "source": [
    "## Modifier l'index en conséquence lorsque l'attribut modifié est indexé\n",
    "Comerncer par créer un index sur l'attribut $a_3$\n",
    "\n",
    "L'attribut $a_3$ étant maintenant indexé, la mise à jour de la question précédente implique d'actualiser l'index sur $a_3$ pour que les rowid des tuples qui contenaient l'ancienne valeur de $a_3$ soient associés à la nouvelle valeur de $a_3$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "id": "3_dcGN_dKaya"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tuple modifis : 1526230\n",
      "done in 0.007 s\n"
     ]
    }
   ],
   "source": [
    "def update_plusieurs_index(index, table, va, addNum):\n",
    "    if v not in index.keys():\n",
    "        if v not in index.keys():\n",
    "            print(\"Err : valeur recherchee not existe\")\n",
    "            return 0\n",
    "    listOfChange = []\n",
    "    page_dir = page_dir_name(table)\n",
    "    \n",
    "    for page, pos in index[v]:\n",
    "        file_path = f\"{page_dir}/page{page}\"\n",
    "        # lire sur le ficher\n",
    "        with open(file_path, 'r') as fp:\n",
    "            lines = fp.readlines()\n",
    "        # modifier le tuple corresponde\n",
    "        line = lines[pos].split(\",\")\n",
    "        line[3] = str(float(line[3]) + addNum)\n",
    "        lines[pos] = \",\".join(line)\n",
    "        # changement de a_3\n",
    "        INDEX_a3[float(line[3])+addNum] = INDEX_a3.pop(float(line[3]))\n",
    "        listOfChange.append(float(line[3]))\n",
    "        # ecrire sur le ficher\n",
    "        with open(file_path, 'w') as fp:\n",
    "            fp.writelines(lines)\n",
    "    return listOfChange\n",
    "\n",
    "\n",
    "INDEX_a3 = creation_index(TABLE, 3)\n",
    "v = 10 * np.random.randint(nb_valeurs_distinctes / 4)\n",
    "print(\"tuple modifis :\", v)\n",
    "\n",
    "t1 = time.time()\n",
    "updated_tuples = update_plusieurs_index(INDEX_a2, TABLE, v, 10)\n",
    "\n",
    "#print(updated_tuples)\n",
    "print(\"done in\", round(time.time() - t1, 3), \"s\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "as_W7xmOKc3l"
   },
   "source": [
    "# Exercice 4 : Persistence\n",
    "\n",
    "Dans cette partie, on veut rendre les index persistents en stockant les entrées triées dans des pages. Cela permet d'utiliser les index plus efficacement en réduisant la durée pour les reconstruire."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Uy8NE3x5KgLj"
   },
   "source": [
    "## Stockage d'un index unique\n",
    "\n",
    "Proposez une solution pour stocker les entrées **triées** d'un index dans plusieurs pages avec une taille de page fixée (10 000 rowids par page).\n",
    "Etudier le cas d'un index unique et celui d'un index non unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "id": "VqSClCOgKl6a"
   },
   "outputs": [],
   "source": [
    "def stockIndexUnique(indexUnique):\n",
    "  # create file path\n",
    "  indexPath = \"indexUniquePages\"\n",
    "  if(os.path.exists(indexPath)):\n",
    "    sh.rmtree(indexPath)\n",
    "  os.makedirs(indexPath)\n",
    "\n",
    "  nbMax = 10000\n",
    "  lines = []\n",
    "  # rerwrite stored lines \n",
    "  for key in sorted(indexUnique.keys()):\n",
    "    lines.append(str(key)+', '+str(indexUnique[key][0])+', '+str(indexUnique[key][1]))\n",
    "  \n",
    "  maxRange = len(lines)//nbMax\n",
    "  if len(lines) % nbMax != 0:\n",
    "    maxRange += 1\n",
    "  # divide into pages \n",
    "  for pageNum in range(maxRange):  \n",
    "    # créer une page\n",
    "    with open(indexPath + f\"/page{pageNum+1}\", \"w\") as fp:\n",
    "      borne = pageNum*nbMax\n",
    "      fp.write('\\n'.join(lines[borne:borne+nbMax]))\n",
    "\n",
    "stockIndexUnique(INDEX_UNIQUE_a0)\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stockIndex(index, num):\n",
    "  # create file path\n",
    "  indexPath = \"indexPages\" + str(num)\n",
    "  if(os.path.exists(indexPath)):\n",
    "    sh.rmtree(indexPath)\n",
    "  os.makedirs(indexPath)\n",
    "\n",
    "  nbMax = 10000\n",
    "  lines = []\n",
    "  # rerwrite stored lines \n",
    "  for key in sorted(index.keys()):\n",
    "    for page, pos in index[key]:\n",
    "      lines.append(str(key)+', '+ str(page) +', ' + str(pos))\n",
    "  \n",
    "  maxRange = len(lines)//nbMax\n",
    "  if len(lines) % nbMax != 0:\n",
    "    maxRange += 1\n",
    "  # divide into pages \n",
    "  for pageNum in range(maxRange):  \n",
    "    # créer une page\n",
    "    with open(indexPath + f\"/page{pageNum+1}\", \"w\") as fp:\n",
    "      borne = pageNum*nbMax\n",
    "      fp.write('\\n'.join(lines[borne:borne+nbMax]))\n",
    "\n",
    "stockIndex(INDEX_a2, 2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5EblJsOaluV7"
   },
   "source": [
    "Montrez que vous pouvez reconstruire les index à partir des entrées stockées dans des pages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "id": "LxCiuoRRl1IL"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "def construireIndexUnique(path):\n",
    "    indexUnique = {}\n",
    "    pageMax = len(os.listdir(path))\n",
    "    for i in range(pageMax):\n",
    "        with open(path + f\"/page{i+1}\", \"r\") as fp:\n",
    "            lines = fp.readlines()\n",
    "        for line in lines:\n",
    "            line = line.split(\",\")\n",
    "            indexUnique[float(line[0])] = (int(line[1]), int(line[2]))\n",
    "    return indexUnique\n",
    "\n",
    "INDEX_UNIQUE_a0_test = construireIndexUnique(\"indexUniquePages\")\n",
    "print(INDEX_UNIQUE_a0 == INDEX_UNIQUE_a0_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "def construireIndex(path):\n",
    "    index = {}\n",
    "    pageMax = len(os.listdir(path))\n",
    "    for i in range(pageMax):\n",
    "        \n",
    "        with open(path + f\"/page{i+1}\", \"r\") as fp:\n",
    "            lines = fp.readlines()\n",
    "        for line in lines:\n",
    "            line = line.split(\",\")\n",
    "            if float(line[0]) in index.keys():\n",
    "                index[float(line[0])].append((int(line[1]), int(line[2])))\n",
    "            else:\n",
    "                index[float(line[0])] = [(int(line[1]), int(line[2]))]\n",
    "    return index\n",
    "\n",
    "INDEX_a2_test = construireIndex(\"indexPages2\")\n",
    "print(INDEX_a2 == INDEX_a2_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SzDPXcGzKjKU"
   },
   "source": [
    "## Adapter en conséquence les opérations de modification de l'index\n",
    "\n",
    "Illustrer le cas :\n",
    "\n",
    "update T set a3 = a3+0.5 where a1=v\n",
    "\n",
    "où la nouvelle valeur $a_3' = a_3 + 0.5$ n'est pas déjà présente dans l'index. Il faut donc insérer une nouvelle clé  dans l'index de l'attribut $a_3$.\n",
    "On suppose qu'il reste de la place dans une page de l'index pour insérer la nouvelle entrée (on peut avoir jusqu'à 12 000 rowids par page d'index)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "id": "y9mXqJeFKmUE"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1869430.0, 2388320.0]\n"
     ]
    }
   ],
   "source": [
    "def updateTest(index_a3, index_a1, val, table):\n",
    "    if val not in index_a1.keys():\n",
    "        print(\"Err : valeur recherchee not existe\")\n",
    "        return 0\n",
    "    # init \n",
    "    listPagePos = index_a1[val]\n",
    "    page_dir = page_dir_name(table)\n",
    "    dataToChange = []\n",
    "    posToChange = []\n",
    "    \n",
    "    for page, pos in listPagePos:\n",
    "        file_path = f\"{page_dir}/page{page}\"\n",
    "        # lire sur le ficher\n",
    "        with open(file_path, 'r') as fp:\n",
    "            lines = fp.readlines()\n",
    "        line = lines[pos].split(\",\")\n",
    "        dataToChange.append(float(line[3]))\n",
    "        posToChange.append((page, pos))\n",
    "    print(dataToChange)\n",
    "    \n",
    "    for i, data in enumerate(dataToChange):\n",
    "        if data+0.5 not in index_a3.keys():\n",
    "            rowid = posToChange[i]\n",
    "            index_a3[data].remove(rowid)\n",
    "            index_a3[data+0.5] = [rowid]\n",
    "            \n",
    "    stockIndex(index_a3, 3)\n",
    "    update_plusieurs(index_a1, table, val, 0.5)\n",
    "\n",
    "INDEX_a1 = creation_index(TABLE, 1)\n",
    "updateTest(INDEX_a3, INDEX_a1, 30, TABLE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WUTS_HFziuGv"
   },
   "source": [
    "# Exercice 5 : Index bitmap\n",
    "*   Proposer un index ayant une structure matricielle (\"bitmap\") pour l'attribut $a_5$. Idem pour l'attribut $a_6$.\n",
    "*   En utilisant les 2 index bitmap, rechercher les tuples de T tels que $a_5 = v_1$ et $a_6 = v_2$ pour deux valeurs $v_1, v_2$ appartenant au domaine de $a_5 \\cap a_6$ .\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_eiRWHoci4l2"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lQDDXVCZi022"
   },
   "source": [
    "\n",
    "## Facultatif: Index couvrant une requête\n",
    "* Illustrer les cas vus en TD pour lesquels il est possible d'obtenir le résultat d'une requête sans lire les données de la table lais seulement les index.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n600I2Vii5FO"
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
