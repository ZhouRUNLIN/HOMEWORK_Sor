{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "77a4b902",
   "metadata": {},
   "source": [
    "Massive parallel programming on GPUs and applications, by Lokman ABBAS TURKI  \n",
    "\n",
    "# 9 Normal cumulative distribution function, using read-only and constant memory allocation, and shared memory \n",
    "\n",
    "## 9.1 Objective\n",
    "\n",
    "The main purpose of this lab is to introduce the student to the use of different memory spaces available on the device. The example presented here is an approximation of the Normal cumulative distribution function that involves the value of some parameters. We consider storing these parameters in a large read-only memory, constant memory, and shared memory. <b>Keep in mind that this is only an exercise in which we show how to use each type of memory space. Indeed, from the beginning of this lab, we already know that the best option for this function is to use registers!</b>\n",
    "\n",
    "The presented example is the continuation of lab number 5 in which we already studied the use of global and local memory allocation and registers.\n",
    "\n",
    "As usual, I urge students to open CUDA documentation, especially:\n",
    "\n",
    "1) the specifications of CUDA API functions within the [CUDA_Runtime_API](https://docs.nvidia.com/cuda/cuda-runtime-api/index.html).\n",
    "2) the examples of how to use the CUDA API functions in [CUDA_C_Programming_Guide](https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "683675c3-4e12-4638-9c69-bda98b3bdf48",
   "metadata": {},
   "source": [
    "## 9.2 Content\n",
    "\n",
    "Compile NP.cu using"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2d6fdf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvcc NP.cu -o NP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "273966c6",
   "metadata": {},
   "source": [
    "Execute NP using (on Microsoft Windows OS ./ is not needed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc6c946a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!./NP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6697bcea",
   "metadata": {},
   "source": [
    "As long as you did not include any additional instruction in the file NP.cu, the execution above is not supposed to return any value. At least, no compilation error is detected by the compiler!\n",
    "\n",
    "In the following questions you will need to include your own code in the file NP.cu, then compile it and execute it. In the following sections, we assume that the device is a pre-Hopper GPU (otherwise add -arch=compute_80 -code=sm_Yy, if Yy>=90).\n",
    "\n",
    "\n",
    "### 9.2.1 Read-only of parameters in global memory\n",
    "\n",
    "For kernel NP_GLOreadOnly_k, we want to keep using global memory Glob as in NP_GLO_k but with the read-only data cache load function __ldg.\n",
    "\n",
    "a) Since we are not allowed to set the values of Glob within the kernel, do it on the host and send it to the device using cudaMemcpyToSymbol.\n",
    "\n",
    "b) Complete the syntax of the kernel NP_GLOreadOnly_k.\n",
    "\n",
    "c) Explain the execution time difference when compared to NP_GLO_k.\n",
    "\n",
    "\n",
    "### 9.2.2 Read-only of parameters in constant memory\n",
    "\n",
    "For kernel NP_CST_k, we replace the use of the large read-only global memory in the previous section with a small constant array Cst.\n",
    "\n",
    "a) Since we are not allowed to set the values of Cst within the kernel, do it on the host and send it to the device using cudaMemcpyToSymbol.\n",
    "\n",
    "b) Complete the syntax of the kernel NP_CST_k.\n",
    "\n",
    "c) Compare the execution time of NP_CST_k to NP_GLOreadOnly_k and to NP_GLO_k using !nvprof ./NP.\n",
    "\n",
    "\n",
    "### 9.2.3 Using shared memory \n",
    "\n",
    "For kernel NP_SHA_k, instead of making the 7 values constant as with CST, we put the values of these parameters in the shared memory.\n",
    "\n",
    "a) How should you set the values in the shared memory within the kernel NP_SHA_k?\n",
    "\n",
    "b) Complete the syntax of the kernel NP_SHA_k.\n",
    "\n",
    "c) Compare the execution time of NP_SHA_k to NP_CST_k and to NP_GLOreadOnly_k using !nvprof ./NP.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fffced9-8f0d-4c5d-bed0-9908fbe43464",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
