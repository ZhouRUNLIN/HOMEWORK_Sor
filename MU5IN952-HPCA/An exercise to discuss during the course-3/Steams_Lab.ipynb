{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8e4e3161-8706-4a8f-a0e8-c0dbaad039cb",
   "metadata": {},
   "source": [
    "Massive parallel programming on GPUs and applications, by Lokman ABBAS TURKI  \n",
    "\n",
    "# 15. Concurrency and asynchronous data transfer\n",
    "\n",
    "## 15.1 Objective\n",
    "\n",
    "In large applications, involving regular data transfer and calling multiple independent kernels at the same time on the GPU, the concurrency of kernel execution and making the data available in the right memory at the right time become crucial. Indeed, GPUs started to be very efficient SIMD (Single Instruction Multiple Data) processors and they became MIMD (Multiple Instruction Multiple Data) processors with large computing resources and bandwidth. It becomes then complicated to feed them with few kernels/data and keep them busy. Using streams on GPUs offers a good solution for managing data transfer and concurrency. The main purpose of this lab is to start using streams with a simple example.\n",
    "\n",
    "Students are encouraged to use the CUDA documentation, in particular:\n",
    "\n",
    "1) the specifications of CUDA API functions within the [CUDA_Runtime_API](https://docs.nvidia.com/cuda/cuda-runtime-api/index.html).\n",
    "2) the examples of how to use the CUDA API functions in [CUDA_C_Programming_Guide](https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "248f1393-e53b-4d0f-9787-502ab785ebf8",
   "metadata": {},
   "source": [
    "## 15.2 Content\n",
    "\n",
    "Compile StreamTest.cu using"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6008012e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvcc StreamTest.cu -o ST"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d674be7",
   "metadata": {},
   "source": [
    "Execute ST using (on Windows machine ./ is not needed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17f78bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "!./ST"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abe0aed3-f261-4cf2-ad03-153685dfe7c4",
   "metadata": {},
   "source": [
    "As long as you did not include any additional instruction in the file Add.cu, the execution above is supposed to return\n",
    "\n",
    "a[i]+b[i] = 399507447,  399507447\\\n",
    "a[i]+b[i] = 399507450,  399507450\\\n",
    "a[i]+b[i] = 399507453,  399507453\\\n",
    "Processing time for doing everything once: 137.347748 ms\\\n",
    "a[i]+b[i] = 399507447,  399507447\\\n",
    "a[i]+b[i] = 399507450,  399507450\\\n",
    "a[i]+b[i] = 399507453,  399507453\\\n",
    "Processing time for doing everything once: 136.145309 ms\\\n",
    "a[i]+b[i] = 399507447,  399507447\\\n",
    "a[i]+b[i] = 399507450,  399507450\\\n",
    "a[i]+b[i] = 399507453,  399507453\n",
    "\n",
    "Of course, the execution time changes at each call and depends on the machine's performance.\n",
    "\n",
    "When launched with -1, the function withoutStream performs standard memory copy and execution of the kernel. When launched with a positive integer, the function withoutStream splits the overall copy and kernel call into smaller frames copy and multiple kernel calls.\n",
    "\n",
    "\n",
    "### 15.2.1 Using streams, withStream function\n",
    "\n",
    "a) Using cudaDeviceGetAttribute, check if the device can concurrently copy memory while executing a kernel and if the device can concurrently execute multiple kernels simultaneously,\n",
    "\n",
    "b) With cudaStream_t define your streams and create them with cudaStreamCreate. At the end of function withStream, use cudaStreamDestroy to destroy streams. \n",
    "\n",
    "c) Use <<<(F+1023)/1024,1024,0,stream[j]>>> to call kernels and cudaMemcpyAsync to copy data\n",
    "\n",
    "d) Do you see any benefits from using streams? \n",
    "\n",
    "\n",
    "### 15.2.2 The impact of the size of the data and the length of the kernel\n",
    "\n",
    "In all these questions, use !nvprof ./ST\n",
    "\n",
    "a) Execute ST for the different sizes provided in the main function\n",
    "\n",
    "b) Uncomment the for loop in add_k and repeat a).\n",
    "\n",
    "c) Replace 50 with 1000 in the for loop in add_k and repeat a)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdee18af-e438-42a7-ae66-5bd8515d8e2b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
