{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8e4e3161-8706-4a8f-a0e8-c0dbaad039cb",
   "metadata": {},
   "source": [
    "Massive parallel programming on GPUs and applications, by Lokman ABBAS TURKI  \n",
    "\n",
    "# 3. Add arrays\n",
    "\n",
    "## 3.1 Objective\n",
    "\n",
    "The main purpose of this lab is to familiarize students with the CUDA API through the implementation of vector addition. Students will gain hands-on experience by writing both GPU kernel code and the corresponding host code for array addition. The host code for memory allocation on GPU and copies from CPU to GPU and from GPU to CPU will serve as examples for future labs. We also introduce the use of unified memory.\n",
    "\n",
    "Students are encouraged to use the CUDA documentation, enabling them to discover:\n",
    "\n",
    "1) the specifications of CUDA API functions within the [CUDA_Runtime_API](https://docs.nvidia.com/cuda/cuda-runtime-api/index.html).\n",
    "2) the examples of how to use the CUDA API functions in [CUDA_C_Programming_Guide](https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "248f1393-e53b-4d0f-9787-502ab785ebf8",
   "metadata": {},
   "source": [
    "## 3.2 Content\n",
    "\n",
    "Your directory has to contain Add.cu file as well as the header file timer.h\n",
    "\n",
    "Compile Add.cu using"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6008012e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvcc Add.cu -o ADD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d674be7",
   "metadata": {},
   "source": [
    "Execute DQ using (on Windows machine ./ is not needed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17f78bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "!./ADD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e625b987-e955-4fc4-bd55-fdec28ed8918",
   "metadata": {},
   "source": [
    "As long as you did not include any additional instruction in the file Add.cu, the execution above is supposed to return\n",
    "\n",
    "( 999999500 ): 999999500\n",
    "( 999999510 ): 999999510\n",
    "( 999999520 ): 999999520\n",
    "( 999999530 ): 999999530\n",
    "( 999999540 ): 999999540\n",
    "CPU Timer for the addition on the CPU of vectors: 0.126\n",
    "\n",
    "Of course, the execution time changes at each call and depends on the host's performance.\n",
    "\n",
    "### 3.2.1 Addition operation on the device with explicit data transfer and CPU timer\n",
    "\n",
    "a) Allocate aGPU, bGPU, cGPU on the GPU using cudaMalloc.\n",
    "\n",
    "b) Transfer the values of a, b to aGPU, bGPU using cudaMemcpy.\n",
    "\n",
    "c) Write the kernel addVect_k that adds aGPU to bGPU and puts the result in cGPU\n",
    "\n",
    "d) Transfer the values of cGPU to c using cudaMemcpy.\n",
    "\n",
    "e) Free the GPU memory using cudaFree.\n",
    "\n",
    "f) Call the kernel addVect_k instead of the function addVect.\n",
    "\n",
    "g) Do not forget to use cudaDeviceSynchronize after calling the kernel.\n",
    "\n",
    "\n",
    "### 3.2.2 Few Optimizations and GPU timer\n",
    "\n",
    "a) Change the CPU timer with the GPU timer using cudaEvent (in milliseconds).\n",
    "\n",
    "b) Check for yourself that using threadIdx.x*gridDim.x + blockIdx.x to access the global memory is a very bad choice.\n",
    "\n",
    "c) What if you compute the execution time of both calling addVect_k and transferring data?\n",
    "\n",
    "d) Profile further your code using: !nvprof ./ADD\n",
    "\n",
    "e) Fix the slow transfer of a, b to aGPU, bGPU using the initialization on the device. Now, we can remove the arrays a, and b.\n",
    "\n",
    "f) Allocate aGPU, bGPU, and cGPU using cudaMallocManaged on the unified memory. Now we can also remove the array c.\n",
    "\n",
    "g) What if we kept the initialization on the host but with all arrays in the unified memory?\n",
    "\n",
    "h) You can speed up solution g) using cudaMemPrefetchAsync of a and b before calling addVect_k."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe988e92-f520-4aba-95c0-5513032894a3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
