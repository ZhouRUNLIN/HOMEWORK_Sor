{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "77a4b902",
   "metadata": {},
   "source": [
    "Massive parallel programming on GPUs and applications, by Lokman ABBAS TURKI  \n",
    "\n",
    "# 1. Device query and error handling\n",
    "\n",
    "## 1.1 Objective\n",
    "\n",
    "The main purpose of this lab is to introduce the student to the CUDA hardware resources and their capabilities. The specification of the GPU will be frequently needed in the following labs. Thus, once the file DevQuery.cu has been configured with the appropriate instructions, it can be compiled and executed whenever students require information about the limitations of the currently utilized device.\n",
    "\n",
    "This lab session serves as the initial opportunity for students to utilize CUDA documentation, enabling them to discover:\n",
    "1) the specifications of CUDA API functions within the [CUDA_Runtime_API](https://docs.nvidia.com/cuda/cuda-runtime-api/index.html).\n",
    "2) the examples of how to use the CUDA API functions in [CUDA_C_Programming_Guide](https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "683675c3-4e12-4638-9c69-bda98b3bdf48",
   "metadata": {},
   "source": [
    "## 1.2 Content\n",
    "\n",
    "Compile DevQuery.cu using"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2d6fdf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvcc DevQuery.cu -o DQ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "273966c6",
   "metadata": {},
   "source": [
    "Execute DQ using (on Microsoft Windows OS ./ is not needed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bc6c946a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!./DQ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6697bcea",
   "metadata": {},
   "source": [
    "As long as you did not include any additional instruction in the file DevQuery.cu, the execution above is not supposed to return any value. At least, no compilation error is detected by the compiler!\n",
    "\n",
    "In the following questions you will need to include your own code in the file DevQuery.cu, then compile it and execute it before answering.\n",
    "\n",
    "\n",
    "### 1.2.1 In the main function, use cudaGetDeviceCount to display the number of available GPUs\n",
    "\n",
    "Hint: use the CUDA documentation\n",
    "\n",
    "\n",
    "### 1.2.2 In the main function, and with device 0, use cudaGetDeviceProperties to display\n",
    "\n",
    "a) The global memory size. What is the largest single-precision floating-point array that can be allocated on the GPU RAM?\n",
    "\n",
    "b) The maximum number maxGridSize of blocks that can be launched. What do you notice?\n",
    "\n",
    "c) The maximum numbers maxThreadsDim and maxThreadsPerBlock of threads per block that can be launched. How do you understand the values given?\n",
    "\n",
    "d) The size of a warp in terms of threads.\n",
    "\n",
    "e) The shared memory size per block.\n",
    "\n",
    "f) The number of registers per block.\n",
    "\n",
    "g) The size of 2D textures. Would it be possible to have it entirely in the cache? \n",
    "\n",
    "h) The number of CUDA cores. (hint: each multiprocessor contains usually 128 CUDA cores)\n",
    "\n",
    "\n",
    "### 1.2.3 Analyze the results from Section 1.2.2\n",
    "\n",
    "a) How long should be the sequences of diverged execution of warps? (hint: search for \"diverge\" keyword in CUDA documentation)\n",
    "\n",
    "b) How do you justify that the number of threads should be (and not must be) a power of 2?\n",
    "\n",
    "c) What can limit a program from launching the maximum number of blocks?\n",
    "\n",
    "d) What can limit a program from launching the maximum number of threads?\n",
    "\n",
    "e) What can trivially make us find a compromise between the number of blocks and the number of threads to be used?\n",
    "\n",
    "\n",
    "### 1.2.4 Recall cudaGetDeviceProperties on the device 20\n",
    "\n",
    "a) What if you change the 0 argument in cudaGetDeviceProperties by 20?\n",
    "\n",
    "b) What kind of cudaError_t do you get?\n",
    "\n",
    "c) Use now testCUDA and see what happens."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
