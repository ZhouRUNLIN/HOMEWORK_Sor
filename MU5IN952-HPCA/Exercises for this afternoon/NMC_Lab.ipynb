{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "77a4b902",
   "metadata": {},
   "source": [
    "Massive parallel programming on GPUs and applications, by Lokman ABBAS TURKI  \n",
    "\n",
    "# 16 From Monte Carlo to nested Monte Carlo simulation\n",
    "\n",
    "## 16.1 Objective\n",
    "\n",
    "This is the second laboratory dedicated to Monte Carlo simulation on GPU. Monte Carlo simulation for linear problems is suitable for parallel architectures. It is therefore a simple and realistic exercise to check the assimilation of the different concepts introduced in this course.\n",
    "We first continue on the optimization of the previous Monte Carlo implementation and perform the reduction directly on the device. Afterwards, we perform a nested Monte Carlo simulation with two layers of parallelization granularities. When the parallel computations are equivalent, in terms of computational complexity and memory storage, it is better to serialize the computations on the inner finer granularity than on the outer coarser granularity.\n",
    "\n",
    "The NP function is used to check the simulation results and thus it should not be modified.\n",
    "\n",
    "As usual, do not forget to use CUDA documentation, especially:\n",
    "\n",
    "1) the specifications of CUDA API functions within the [CUDA_Runtime_API](https://docs.nvidia.com/cuda/cuda-runtime-api/index.html).\n",
    "2) the examples of how to use the CUDA API functions in [CUDA_C_Programming_Guide](https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html)\n",
    "\n",
    "Add to this,\n",
    "\n",
    "3) the documentation of the CUDA random number generation library [cuRAND Library](https://docs.nvidia.com/cuda/curand/index.html).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "683675c3-4e12-4638-9c69-bda98b3bdf48",
   "metadata": {},
   "source": [
    "## 16.2 Content\n",
    "\n",
    "Copy your previous solution MC.cu, then compile it using"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2d6fdf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvcc MC.cu -o MC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "273966c6",
   "metadata": {},
   "source": [
    "Execute MC using (on Microsoft Windows OS ./ is not needed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc6c946a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!./MC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6697bcea",
   "metadata": {},
   "source": [
    "### 16.2.1 Monte Carlo simulation MC_k2, with a reduction on the device\n",
    "\n",
    "sum and sum2 are two variables that should respectively contain the estimation of the first and the second moment of the actualized payoff: \n",
    "exp(-rT)*(x-K)_+. This time, their computation with an average is performed on the device. Thus, after simulating the realizations of the actualized payoff on the device, we perform the reduction on the device using shared memory.\n",
    "\n",
    "a) Define MC_k2 which does the same operations found in MC_k1 plus the reduction part. \n",
    "\n",
    "b) Would it be possible to print directly the values of sum and sum2 within MC_k2?\n",
    "\n",
    "c) Does the reduction change significantly the execution time of the kernel MC_k2 when compared to MC_k1?\n",
    "\n",
    "\n",
    "### 16.2.2 Nested Monte Carlo simulation, MC_nested_k and init_curand_nested_state_k\n",
    "\n",
    "When we have many Monte Carlo simulations to perform at the same time, it is tempting to serialize with respect to the number of Monte Carlo simulations. However, when these Monte Carlo simulations are equivalent (like with nested Monte Carlo), it is more effective to parallelize first with respect to the number Monte Carlo simulations, then parallelize as much as possible with respect to the number of trajectories. This is exactly what will be done here.\n",
    "\n",
    "\n",
    "a) How the number of Monte Carlo simulations m > 65536 should be indexed? with blockIdx.x? with blockIdx.y? with threadIdx.x? A combination?\n",
    "\n",
    "b) How should we index the number of simulated trajectories? What about the global memory limit? What should we serialize?\n",
    "\n",
    "c) The number of computed sum and sum2 is equal to m. Use the unified memory for sum and sum2.\n",
    "\n",
    "d) Define the kernels MC_nested_k and init_curand_nested_state_k, then check the result and the execution time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fffced9-8f0d-4c5d-bed0-9908fbe43464",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
